{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "with open('../data/pitt_cookie_dataset.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    # 1. Remove [...] and (...)\n",
    "    s = re.sub(r'\\[.*?\\]', '', s)\n",
    "    s = re.sub(r'\\(.*?\\)', '', s)\n",
    "\n",
    "\n",
    "    # 2. Remove all occurrences of \"<\" and \">\", even if they're next to other characters\n",
    "    s = s.replace('+<','').replace('<', '').replace('>', '')\n",
    "\n",
    "    # 3. Remove \"&=\", \"&-\", \"&+\"\n",
    "    s = re.sub(r'&[-\\+]', '', s)\n",
    "    s = re.sub(r'&=\\S*\\b\\s*', '', s)\n",
    "\n",
    "\n",
    "    # 4. Remove \"+/\" and \"+//\"\n",
    "    s = s.replace('+//?','?').replace('+//.', '.').replace('+/.', '.').replace('/.', '.').replace('+/?', '?')\n",
    "\n",
    "    # 5. Remove \"‡\"\n",
    "    s = s.replace('‡', '')\n",
    "\n",
    "    # 6. Replace \"+...\" with \".\" and \"+..?\" with \"?\"\n",
    "    s = s.replace('+...', '.').replace('+..?', '?')\n",
    "\n",
    "    # 7. Remove \"+\\\"\" and \"+,\"\n",
    "    s = s.replace('+\"', '').replace('+,','')\n",
    "\n",
    "    # 8. Remove all phrases containing \"@\"\n",
    "    s = re.sub(r'\\b\\w*@\\w*\\b\\s*', '', s)\n",
    "    s = re.sub(r'\\b(kɜ˞@u|mɪndə˞@u|mɪdə˞@u|mɪdnə˞@u|kɪtʃə˞@u)\\b\\s*', '', s)\n",
    "    \n",
    "    # 9. Remove all ':'\n",
    "    s = s.replace(':', '')\n",
    "\n",
    "    # Remove period\n",
    "    # s = re.sub(r'\\.', '', s)\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = []\n",
    "\n",
    "for key in list(data.keys()):\n",
    "    # print(key)\n",
    "    if key == \"dementia\":\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    group = data[key]\n",
    "    for file_key in data[key]:\n",
    "        # print(file_key)\n",
    "        file = group[file_key]\n",
    "        result = ''\n",
    "        lines = file['lines']\n",
    "        index = file['index']\n",
    "        for line in lines:\n",
    "            if line['speaker'] == \"PAR\":\n",
    "                utter = clean_string(line['utterance'])\n",
    "                # utter = line['utterance']\n",
    "                if result == '':\n",
    "                    result = utter\n",
    "                      #first line in a file\n",
    "                else:\n",
    "                    result = result + \"\\n \" + utter #separator token\n",
    "        # print(result)\n",
    "        sentences_list.append({\"index\": index, \"label\": label, \"line\":result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/clean_v1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentences_list, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Split_data import split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    250\n",
      "0    200\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    56\n",
      "0    43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test = split_dataset(file_path = \"../data/clean_v1.json\", label_column=\"label\", random_state=42, specific=True)\n",
    "train = train.set_index('index')\n",
    "train = train.sort_index()\n",
    "test = test.set_index('index')\n",
    "text = test.sort_index()\n",
    "print(train.label.value_counts())\n",
    "print(test.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/train_v1_450.csv\")\n",
    "test.to_csv(\"../data/test_v1_99.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 11, 'label': 1, 'line': \"kids are trying to get a s s s s s s . \\n it's full of  it's full of uh mistakes . \\n it's full o mistakes . \\n it's full of mistakes . \\n he's changin   taking cookie jar .  \\n that's all .  \\n the mother's just drying the dishes . \\n n n n n n n s s n s xxx from the from xxx . \\n this is uh . \"} \n",
      "\n",
      "{'index': 72, 'label': 1, 'line': \" and I will tell you what's g .  \\n oh boy .  \\n well  the little boy is reaching for a cookie . \\n and his s stool is fallin over . \\n and the little girl is beggin him to give her one . \\n and she's pointin to her mouth . \\n she wants to eat it . \\n uh their mama is doin the dishes . \\n the water's runnin over the sink . \\n that's a mess . \\n and then she's not even lookin at them . \\n dryin dishes .  \\n I think she's lookin out the window . \\n it's a nice yard out there . \\n two cups and  and a dish finished .  \\n xxx anything else ?  \"} \n",
      "\n",
      "{'index': 151, 'label': 1, 'line': \"the uh young fellow is s standing on the step ladder which is . \\n it's a stool which is getting ready to fall . \\n he's handing  he's getting a cookie out while he's handing one to the sister . \\n the top is falling off of the cookie jar . \\n the girl is standin on the floor with her hand reachin up for the cookie while she has her right hand up to her mouth . \\n I think she's tellin him to watch it . \\n he's at the cupboard with the door open . \\n the mother has her back turned towards them . \\n the water is overflowing from the faucet into the sink onto the floor while she wipes  uh while she dries uh a dish . \\n and she doesn't even hear or know what's going on . \\n there the cupboard doors are closed . \\n the window is open or closed and you can see outside . \\n the path flowers and so forth .  \\n now I know I'm missing something .  \\n she's standing in the water . \\n  the faucet  the sink is overflowing . \\n two cups and a plate are there . \\n that's all I can see .  \"} \n",
      "\n",
      "{'index': 192, 'label': 1, 'line': \"uh the water's overflowing in the sink . \\n the woman's wa drying dishes . \\n uh the boy is uh tipping over his s stool . \\n he is also reaching into the cookie jar . \\n the girl is reaching up for a cookie and she is laughing . \\n and uh I think that's it .  \"} \n",
      "\n",
      "{'index': 220, 'label': 1, 'line': \"well  the boy is in the cookie jar . \\n and the  da and his sister is trying to uh take it from him . \\n and he's uh on a stool going like this . \\n and uh then there's uh l uh s a female over here with a plate in her hand that she's dryin dishes .  \\n water or  the  uh s the  s  the water went ov overboard on this one on the  m on this s si sink . \\n it's on the floor . \\n and the boy's uh cookin  uh gettin cookies . \\n and his chair   s wobblin . \\n right here „ see .  \"} \n",
      "\n",
      "{'index': 267, 'label': 1, 'line': \" what do ?  \\n mhm  mhm .  \\n do you want them crossed out or just say it out loud ?  \\n  okay  uh the little boy's climbing the cri cookie jar . \\n uh he has  the little boy has  has cookies  a cookie in his hand that he got by climbing the step ladder which is ready to fall . \\n the sister is asking for uh something to eat . \\n she has started little and wants some more . \\n uh let's see now .  \\n the mother  the mother has s s a small mess in the kitchen lucky it's  lucky it's small . \\n uh the mother is now washing and dr no yeah  she's washing and drying the dishes in the kitchen . \\n her water has spilled over terribly bad . \\n and looks like sister's back to try for some more cookies . \\n okay .  \"} \n",
      "\n",
      "{'index': 532, 'label': 0, 'line': \" first of all the sink is overflowing . \\n  mother is washing dishes or an adult is washing dishes . \\n there are two children in the cookie jar . \\n one of em is on a stool . \\n and the stool's overturning . \\n the little girl is reaching for a cookie from the little boy as the s s stool turn  falls over . \\n there's a window . \\n and the bushes and path outside the window .  \\n and a glimpse of another window .  \\n and another part of the house .  \\n there are curtains with tie-backs . \\n there are dishes . \\n  there is dish towels   there are dish towels . \\n um  well maybe there are  only one .  \\n there's at least only one dish towel . \\n I thought I  s I looked at one dish towel .  \\n two cups a plate cabinets .  \\n  apron .  \\n  glass and trees .  \\n I don't think I can xxx .  \\n floor .  \\n  counter space .  \\n  did I xxx .  \"} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in sentences_list:\n",
    "    a = i[\"line\"].split(\"\\n\")\n",
    "    for line in a:\n",
    "        if 's s s' in line:\n",
    "            print(i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_list) == len(data[\"dementia\"]) + len(data[\"control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_count_special_tokens(sentences_list):\n",
    "    # special_tokens_dict = []\n",
    "    all_special_tokens = []\n",
    "    # Updated regex pattern to match phonetic symbols, <, &, ‡, phrases between (), and other special tokens\n",
    "    special_token_pattern = re.compile(\n",
    "        r'\\[.*?\\]|\\&-\\w+|\\+|\\:|\\=.*|[:;=]|\\(\\.\\)|\\(\\.\\.\\)|\\/\\/|\\/|<.*?>|\\(.*?\\)|\\(g\\)|\\n|‡|<|&|'\n",
    "        r'\\bdʌ@u\\b|\\bkɪtʃə˞@u\\b|\\bmɪndə˞@u\\b|\\bmɪdə˞@u\\b|\\bmɪdnə˞@u\\b'\n",
    "    )\n",
    "    \n",
    "    for sentence in sentences_list:\n",
    "        line = sentence['line']\n",
    "        \n",
    "        # Find all special tokens\n",
    "        special_tokens = re.findall(special_token_pattern, line)\n",
    "        all_special_tokens.extend(special_tokens)  # Collect all tokens for frequency counting\n",
    "        \n",
    "        \n",
    "        # Append results to list\n",
    "        # special_tokens_dict.append({\n",
    "        #     'original_line': line,\n",
    "        #     'special_tokens': special_tokens,\n",
    "        #     'cleaned_line': cleaned_line.strip()  # Strip extra whitespace\n",
    "        # })\n",
    "    \n",
    "    # Count frequency of each special token\n",
    "    special_token_counts = Counter(all_special_tokens)\n",
    "    sorted_special_token_counts = dict(sorted(special_token_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    return sorted_special_token_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of each special token:\n",
      "\n",
      ": 6530\n"
     ]
    }
   ],
   "source": [
    "sorted_special_token_counts = find_and_count_special_tokens(sentences_list)\n",
    "\n",
    "print(\"Frequency of each special token:\")\n",
    "for token, count in sorted_special_token_counts.items():\n",
    "    print(f\"{token}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
